{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbRtcmcJ9ZdZiGVrYNVKSC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hramac/Exploring-India-s-COVID-19-Journey-A-Case-Study-Analysis/blob/main/Exploring_India's_COVID_19_Journey_A_Case_Study_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing:\n",
        "To begin the project, the first step is to preprocess the available datasets. There are six datasets in total, out of which four datasets require cleaning, while the remaining two are already in suitable condition. Initially, we will focus on making the necessary changes and cleaning the four datasets using Python. Once the cleaning process is complete, we will upload all six datasets, including the four cleaned datasets, into the database. This will enable us to proceed with SQL tasks and further analysis for the project.\n",
        "\n",
        "Data Cleaning for agedistribution_2016_estimates.csv:\n",
        "Data Cleaning for 'agedistribution_2016_estimates' is a process of renaming the appropriate columns in a dataset containing data. This improves the quality and usability of the data for analysis and modeling purposes.\n",
        "\n",
        "How to finish the current Task?\n",
        "To complete the current task, write your Python code in the \"\"\"rename_columns()\"\"\" function in the \"\"\"agedistribution_2016_estimates.py\"\"\" file, and then click on \"\"\"Run Test\"\"\" to finish the task.\n",
        "\n",
        "To execute the entire project, choose the \"Terminal\" section and press the \"Run Project\" option."
      ],
      "metadata": {
        "id": "LDNS0vX2TF5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#Task1\n",
        "#Loading the data\n",
        "def read_data_from_csv():\n",
        "    #Read the dataset\n",
        "    df = pd.read_csv('agedistribution_2016_estimates.csv')\n",
        "    return df\n",
        "\n",
        "\n",
        "#Task 2: Renaming the Columns\n",
        "def rename_columns():\n",
        "    data=read_data_from_csv()\n",
        "\n",
        "    # Rename the column names\n",
        "    data.rename(columns={'Age': 'Age_group', 'M': 'Male', 'F': 'Female', 'Tot': 'Total'}, inplace=True)\n",
        "\n",
        "    # Export cleaned dataset to a new CSV file named \"agedistribution_2016_estimates_cleaned.csv\"\n",
        "    data.to_csv('agedistribution_2016_estimates_cleaned.csv', index=False)\n",
        "\n",
        "    # export cleaned Dataset to newcsv file named \"agedistribution_2016_estimates_cleaned.csv\"\n",
        "    return data\n",
        "\n",
        "#Do not Delete the Following function\n",
        "def task_runner():\n",
        "    rename_columns()\n",
        "\n",
        "task_runner()"
      ],
      "metadata": {
        "id": "UKakD_A7QEiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning for death_and_recovery.csv:\n",
        "Removing Unwanted Columns :\n",
        "Data cleaning for \"\"death_and_recovery\"\" involves removing unwanted columns from a dataset. For the purposes of analysis and modelling, this enhances the quality and usability of the data.\n",
        "\n",
        "How to finish the current Task?\n",
        "To complete the current task, write your Python code in the \"\"data_cleaning()\"\" function in the \"\"death_and_recovery.py\"\" file, and then click on \"\"Run Test\"\" to finish the task."
      ],
      "metadata": {
        "id": "-xoDtXi5TNyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Task 1\n",
        "# Loading the data\n",
        "def read_data_from_csv():\n",
        "    df = pd.read_csv('death_and_recovery.csv')\n",
        "    return df\n",
        "\n",
        "def data_cleaning():\n",
        "    # Call read_data_from_csv() function to get the dataframe\n",
        "    data = read_data_from_csv()\n",
        "\n",
        "    # Remove unwanted columns (comorbidity, State_code)\n",
        "    unwanted_columns = ['comorbidity', 'State_code']\n",
        "    data = data.drop(columns=unwanted_columns)\n",
        "\n",
        "    # Export cleaned dataset to a new CSV file named \"death_and_recovery_cleaned.csv\"\n",
        "    data.to_csv('death_and_recovery_cleaned.csv', index=False)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Do not delete the following function\n",
        "def task_runner():\n",
        "    data_cleaning()\n",
        "\n",
        "task_runner()\n"
      ],
      "metadata": {
        "id": "KVg_Y-CTSeZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning for hospitalbeds.csv:\n",
        "Data Cleaning for 'hospitalbeds' is a process of renaming the appropriate columns in a dataset containing data. This improves the quality and usability of the data for analysis and modeling purposes.\n",
        "\n",
        "How to finish the current Task?\n",
        "To complete the current task, write your Python code in the \"\"\"rename_columns()\"\"\" function in the \"\"\"hospitalbeds.py\"\"\" file, and then click on \"\"\"Run Test\"\"\" to finish the task."
      ],
      "metadata": {
        "id": "NSlGMitITYWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Task 1: Loading the data\n",
        "def read_data_from_csv():\n",
        "    # Read the dataset\n",
        "    df = pd.read_csv('hospitalbeds.csv')\n",
        "    return df\n",
        "\n",
        "# Task 2: Renaming the Columns\n",
        "def rename_columns():\n",
        "    data = read_data_from_csv()\n",
        "\n",
        "    # Rename the columns\n",
        "    data = data.rename(columns={'serial': 'sno',\n",
        "                                'state': 'State_UT',\n",
        "                                'Hosp_Aval': 'Hospitals_Available',\n",
        "                                'Beds_Aval': 'Beds_Available',\n",
        "                                'Pop_beds': 'Population_beds'})\n",
        "\n",
        "    # Export cleaned Dataset to a new CSV file named \"hospitalbeds_cleaned.csv\"\n",
        "    data.to_csv('hospitalbeds_cleaned.csv', index=False)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Do not delete the following function\n",
        "def task_runner():\n",
        "    rename_columns()\n",
        "\n",
        "task_runner()\n"
      ],
      "metadata": {
        "id": "RiWY_e9mTZRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning for statewisedata.csv:\n",
        "Removing Unwanted Columns :\n",
        "Data cleaning for \"\"\"statewisedata\"\"\" involves removing unwanted columns from a dataset. For the purposes of analysis and modelling, this enhances the quality and usability of the data.\n",
        "\n",
        "How to finish the current Task?\n",
        "To complete the current task, write your Python code in the \"\"\"data_cleaning()\"\"\" function in the \"\"\"statewisedata.py\"\"\" file, and then click on \"\"\"Run Test\"\"\" to finish the task."
      ],
      "metadata": {
        "id": "15wgKqSUTzbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Task 1\n",
        "# Loading the data\n",
        "def read_data_from_csv():\n",
        "    df = pd.read_csv('statewisedata.csv')\n",
        "    return df\n",
        "\n",
        "def data_cleaning():\n",
        "    # Call remove_unwanted_columns() function to get dataframe\n",
        "    data = read_data_from_csv()\n",
        "\n",
        "    # Remove unwanted columns (Delta_Confirmed, Delta_Recovered, Delta_Deaths)\n",
        "    data = data.drop(['Delta_Confirmed', 'Delta_Recovered', 'Delta_Deaths'], axis=1)\n",
        "\n",
        "    # Export cleaned Dataset to new CSV file named \"statewisedata_cleaned.csv\"\n",
        "    data.to_csv('statewisedata_cleaned.csv', index=False)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Do not Delete the Following function\n",
        "def task_runner():\n",
        "    data_cleaning()\n",
        "\n",
        "task_runner()\n"
      ],
      "metadata": {
        "id": "YJBRM0qeT1Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate tables using the cleaned dataset:\n",
        "Download the cleaned dataset by clicking on the file name from File explorer\n",
        "\n",
        "Utilize the MySQL database information provided in \"\"Database info\"\" to manually create the following tables for the cleaned dataset\n",
        "\n",
        "agedistribution_2016_estimates\n",
        "death_and_recovery\n",
        "hospitalbeds\n",
        "datewisepatients\n",
        "icmrtestingdata\n",
        "statewisedata\n",
        "How to finish the current Task?\n",
        "To complete the task, enter the database information provided in the Database Info tab into the \"\"db.py\"\" file and press Ctrl+S to save it. After that, use the provided login information to access the database by clicking the \"\"localhost\"\" link located on the Database Info tab. Once there, you need to upload the required datasets in the perticular database mentioned in the \"\"db.py\"\" file. and then click on \"\"Run test\"\" to complete the task."
      ],
      "metadata": {
        "id": "7rZbfC46UX2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Database Details\n",
        "Host: localhost | Database: b5b10fea\n",
        "\n",
        "Username: b5b10fea | Password: Cab#22se"
      ],
      "metadata": {
        "id": "7khM0PLRUy7y"
      }
    }
  ]
}